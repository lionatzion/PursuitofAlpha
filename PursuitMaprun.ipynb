{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDjlMqDaMCNKkEZwnFC6ro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lionatzion/PursuitofAlpha/blob/main/PursuitMaprun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw_CEgoCo4Qa",
        "outputId": "9ac3af23-318d-4b0e-e06a-70d7a8bfab07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Scaffold recreated and zipped to: /content/drive/MyDrive/quant_backtest_ml_scaffold.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os, textwrap, zipfile, shutil\n",
        "\n",
        "# 1. Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define paths\n",
        "project_root = '/content/drive/MyDrive/quant_backtest_ml'\n",
        "zip_path     = '/content/drive/MyDrive/quant_backtest_ml_scaffold.zip'\n",
        "\n",
        "# 3. Remove any old project folder, then recreate every subdirectory\n",
        "if os.path.isdir(project_root):\n",
        "    shutil.rmtree(project_root)\n",
        "\n",
        "# List of all subdirectories ('' = project root itself)\n",
        "subdirs = [\n",
        "    '',\n",
        "    'modules',\n",
        "    'pipelines',\n",
        "    'data/raw',\n",
        "    'data/processed',\n",
        "    'data/altdata',\n",
        "    'models/hf/finbert',\n",
        "    'models/hf/finbert-tone',\n",
        "    'models/trained',\n",
        "    'notebooks',\n",
        "    'logs'\n",
        "]\n",
        "for sub in subdirs:\n",
        "    os.makedirs(os.path.join(project_root, sub), exist_ok=True)\n",
        "\n",
        "# Helper to write text files\n",
        "def write(path, content):\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(textwrap.dedent(content).lstrip())\n",
        "\n",
        "# 4. Top‐level files\n",
        "write(f'{project_root}/README.md', \"\"\"\n",
        "    # Quant Backtest Machine Learning Project\n",
        "\n",
        "    This scaffold sets up a modular project for quantitative trading strategies with ML and sentiment analysis.\n",
        "\"\"\")\n",
        "write(f'{project_root}/requirements.txt', \"\"\"\n",
        "    pandas\n",
        "    numpy\n",
        "    yfinance\n",
        "    scikit-learn\n",
        "    backtrader\n",
        "    ta\n",
        "    transformers\n",
        "    torch\n",
        "    joblib\n",
        "    optuna\n",
        "    google-cloud-storage\n",
        "    google-cloud-logging\n",
        "\"\"\")\n",
        "write(f'{project_root}/.env_template', \"\"\"\n",
        "    HUGGINGFACE_TOKEN=\n",
        "    TIINGO_API_KEY=\n",
        "    POLYGON_API_KEY=\n",
        "    NEWSAPI_KEY=\n",
        "    GOOGLE_APPLICATION_CREDENTIALS=\n",
        "\"\"\")\n",
        "write(f'{project_root}/config.yaml', \"\"\"\n",
        "    project_root: \"/content/drive/MyDrive/quant_backtest_ml\"\n",
        "    data:\n",
        "      raw: \"data/raw\"\n",
        "      processed: \"data/processed\"\n",
        "      altdata: \"data/altdata\"\n",
        "    models:\n",
        "      hf:\n",
        "        finbert: \"models/hf/finbert\"\n",
        "        tone:   \"models/hf/finbert-tone\"\n",
        "      trained: \"models/trained\"\n",
        "    tickers: [\"AAPL\", \"SPY\", \"QQQ\"]\n",
        "    backtest:\n",
        "      start_date: \"2019-01-01\"\n",
        "      end_date:   \"2024-12-31\"\n",
        "      interval:   \"1h\"\n",
        "\"\"\")\n",
        "write(f'{project_root}/Dockerfile', \"\"\"\n",
        "    FROM python:3.10-slim\n",
        "    COPY requirements.txt .\n",
        "    RUN pip install --no-cache-dir -r requirements.txt\n",
        "    COPY . /app\n",
        "    WORKDIR /app\n",
        "    CMD [\"python\", \"pipelines/full_pipeline.py\"]\n",
        "\"\"\")\n",
        "write(f'{project_root}/docker-compose.yml', \"\"\"\n",
        "    version: '3.8'\n",
        "    services:\n",
        "      app:\n",
        "        build: .\n",
        "        volumes:\n",
        "          - .:/app\n",
        "        command: python pipelines/full_pipeline.py\n",
        "\"\"\")\n",
        "\n",
        "# 5. modules/\n",
        "modules = {\n",
        "    'data_ingestion.py': 'def download_data():\\n    pass\\n',\n",
        "    'feature_engineering.py': 'def create_volume_bars():\\n    pass\\n\\ndef add_indicators():\\n    pass\\n',\n",
        "    'model_training.py': 'def prepare_features():\\n    pass\\n\\ndef train_classifier():\\n    pass\\n',\n",
        "    'model_evaluation.py': 'def evaluate_model():\\n    pass\\n',\n",
        "    'sentiment_analysis.py': 'def score_sentiment(text):\\n    pass\\n',\n",
        "    'backtesting_workflow.py': 'def run_backtest():\\n    pass\\n',\n",
        "}\n",
        "for fn, content in modules.items():\n",
        "    write(f'{project_root}/modules/{fn}', content)\n",
        "\n",
        "# 6. pipelines/\n",
        "pipelines = {\n",
        "    'train_pipeline.py': 'from modules.model_training import train_classifier\\n\\ndef main():\\n    train_classifier()\\n\\nif __name__==\"__main__\":\\n    main()\\n',\n",
        "    'backtest_pipeline.py': 'from modules.backtesting_workflow import run_backtest\\n\\ndef main():\\n    run_backtest()\\n\\nif __name__==\"__main__\":\\n    main()\\n',\n",
        "    'full_pipeline.py': 'import subprocess\\n\\ndef main():\\n    subprocess.run([\"python\",\"pipelines/train_pipeline.py\"])\\n    subprocess.run([\"python\",\"pipelines/backtest_pipeline.py\"])\\n\\nif __name__==\"__main__\":\\n    main()\\n',\n",
        "}\n",
        "for fn, content in pipelines.items():\n",
        "    write(f'{project_root}/pipelines/{fn}', content)\n",
        "\n",
        "# 7. Zip everything\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, dirs, files in os.walk(project_root):\n",
        "        for file in files:\n",
        "            full = os.path.join(root, file)\n",
        "            rel  = os.path.relpath(full, '/content/drive/MyDrive')\n",
        "            zf.write(full, rel)\n",
        "\n",
        "print(f\"✅ Scaffold recreated and zipped to: {zip_path}\")\n"
      ]
    }
  ]
}